{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of genuine tweets: 2839364\n",
      "Total number of bot tweets: 1610035\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows in each .csv file\n",
    "\n",
    "filename_gen = \"cresci-2017/genuine_accounts.csv/tweets.csv\"\n",
    "filename_bot = \"cresci-2017/social_spambots_1.csv/tweets.csv\"\n",
    "\n",
    "M_gen = sum(1 for l in io.open(filename_gen, encoding='latin-1'))\n",
    "M_bot = sum(1 for l in io.open(filename_bot, encoding='latin-1'))\n",
    "\n",
    "print(\"Total number of genuine tweets: %d\" % M_gen)\n",
    "print(\"Total number of bot tweets: %d\" % M_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for genuine tweets: 2839\n",
      "Sample size for bot tweets: 1610\n"
     ]
    }
   ],
   "source": [
    "# Import only a sample from both .csv files \n",
    "# (sample size = original size / scaling_factor)\n",
    "# Source: http://nikgrozev.com/2015/06/16/fast-and-simple-sampling-in-pandas-when-loading-data-from-files/\n",
    "\n",
    "scaling_factor = 1000\n",
    "skipids_gen = [x for x in range(1, M_gen) if x % scaling_factor != 0]\n",
    "skipids_bot = [x for x in range(1, M_bot) if x % scaling_factor != 0]\n",
    "\n",
    "data_gen = pd.read_csv(filename_gen, skiprows = skipids_gen)\n",
    "data_bot = pd.read_csv(filename_bot, skiprows = skipids_bot)\n",
    "\n",
    "m_gen = len(data_gen)\n",
    "m_bot = len(data_bot)\n",
    "\n",
    "print(\"Sample size for genuine tweets: %d\" % m_gen)\n",
    "print(\"Sample size for bot tweets: %d\" % m_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2_gen = data_gen[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions']]\n",
    "data2_bot = data_bot[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions']]\n",
    "\n",
    "genSummary = data2_gen.mean()\n",
    "botSummary = data2_bot.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of genuine users: 3475\n",
      "Total number of bot users: 992\n"
     ]
    }
   ],
   "source": [
    "filename_gen_user = \"cresci-2017/genuine_accounts.csv/users.csv\"\n",
    "filename_bot_user = \"cresci-2017/social_spambots_1.csv/users.csv\"\n",
    "\n",
    "m_gen_user = sum(1 for l in io.open(filename_gen_user, encoding='latin-1'))\n",
    "m_bot_user = sum(1 for l in io.open(filename_bot_user, encoding='latin-1'))\n",
    "\n",
    "print(\"Total number of genuine users: %d\" % m_gen_user)\n",
    "print(\"Total number of bot users: %d\" % m_bot_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_user = pd.read_csv(filename_gen_user)\n",
    "data_bot_user = pd.read_csv(filename_bot_user)\n",
    "\n",
    "data_gen_user_2 = data_gen_user[['id','name','statuses_count','followers_count','friends_count','favourites_count','listed_count','default_profile_image']]\n",
    "data_bot_user_2 = data_bot_user[['id','name','statuses_count','followers_count','friends_count','favourites_count','listed_count','default_profile_image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fucking annoying shit that didn't even mean anything\n",
    "# But we didn't really know what we were doing anyways...\n",
    "\n",
    "# data_gen_user_2 = data_gen_user[['id','name','statuses_count','followers_count','friends_count','favourites_count','listed_count','default_profile_image']]\n",
    "# data_bot_user_2 = data_bot_user[['id','name','statuses_count','followers_count','friends_count','favourites_count','listed_count','default_profile_image']]\n",
    "# genUserColorData = data_gen_user[['profile_text_color','profile_sidebar_border_color','profile_sidebar_fill_color','profile_background_color','profile_link_color']]\n",
    "# botUserColorData = data_bot_user[['profile_text_color','profile_sidebar_border_color','profile_sidebar_fill_color','profile_background_color','profile_link_color']]\n",
    "# genUserColorNotSelected = genUserColorData.applymap(lambda x: x==\"000000\").all(axis=1)\n",
    "# botUserColorNotSelected = botUserColorData.applymap(lambda x: x==\"000000\").all(axis=1)\n",
    "# data_gen_user_2.assign(colorNotSelected = genUserColorNotSelected)\n",
    "# data_bot_user_2.assign(colorNotSelected = botUserColorNotSelected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number-of-duplicate-tweets    0.102926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: might be a good idea to reread and check whether or not it's doing what it's supposed to be doing\n",
    "\n",
    "tweets = data_bot['text']\n",
    "index_sets = [np.argwhere(i==tweets) for i in np.unique(tweets)]\n",
    "\n",
    "a = np.zeros((len(data_bot_user),1))\n",
    "noDuplicateTweets = pd.DataFrame(a, columns = ['number-of-duplicate-tweets'])\n",
    "for i in range(0,len(index_sets)-1):\n",
    "    index_set = index_sets[i]\n",
    "    idNo = data_bot.loc[index_sets[i][0,0],\"user_id\"]\n",
    "    idIndex = data_bot_user['id'][data_bot_user['id'] == idNo].index.values.astype(int)[0]\n",
    "    if len(index_set) > 1:\n",
    "        noDuplicateTweets.loc[idIndex] += 1\n",
    "        \n",
    "np.mean(noDuplicateTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number-of-duplicate-tweets    0.000576\n",
       "dtype: float64"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: might be a good idea to reread and check whether or not it's doing what it's supposed to be doing\n",
    "\n",
    "tweets = data_gen['text'].astype(str)\n",
    "index_sets = [np.argwhere(i==tweets) for i in np.unique(tweets)]\n",
    "\n",
    "a = np.zeros((len(data_gen_user),1))\n",
    "noDuplicateTweets = pd.DataFrame(a, columns = ['number-of-duplicate-tweets'])\n",
    "for i in range(0,len(index_sets)-1):\n",
    "    index_set = index_sets[i]\n",
    "    idNo = data_gen.loc[index_sets[i][0,0],\"user_id\"]\n",
    "    idIndex = data_gen_user['id'][data_gen_user['id'] == idNo].index.values.astype(int)[0]\n",
    "    if len(index_set) > 1:\n",
    "        noDuplicateTweets.loc[idIndex] += 1\n",
    "        \n",
    "np.mean(noDuplicateTweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
